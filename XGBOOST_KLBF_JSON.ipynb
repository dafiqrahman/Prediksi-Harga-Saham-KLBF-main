{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "57fab3da",
      "metadata": {
        "id": "57fab3da"
      },
      "source": [
        "### **1. Mengimpor Library**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyswarm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn9iM4UetvzI",
        "outputId": "f60d1ac9-b80f-48d9-b0fd-011c03fbf5dd"
      },
      "id": "Sn9iM4UetvzI",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyswarm\n",
            "  Downloading pyswarm-0.6.tar.gz (4.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyswarm) (1.26.4)\n",
            "Building wheels for collected packages: pyswarm\n",
            "  Building wheel for pyswarm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyswarm: filename=pyswarm-0.6-py3-none-any.whl size=4464 sha256=d1463409f5698dd34b15a6b5d0c751a2eb9993b19d94efdd9b045750cb70857a\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/67/40/62fa158f497f942277cbab8199b05cb61c571ab324e67ad0d6\n",
            "Successfully built pyswarm\n",
            "Installing collected packages: pyswarm\n",
            "Successfully installed pyswarm-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---MULAI---\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import time\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from xgboost import XGBRegressor\n",
        "from pyswarm import pso\n",
        "#---SELESAI---"
      ],
      "metadata": {
        "id": "s2xWBighnZBE"
      },
      "id": "s2xWBighnZBE",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Mengambil Data dari Yahoo Finance**"
      ],
      "metadata": {
        "id": "ZdW26fUPnmm1"
      },
      "id": "ZdW26fUPnmm1"
    },
    {
      "cell_type": "code",
      "source": [
        "#---MULAI---\n",
        "# Ticker saham\n",
        "ticker = \"KLBF.JK\"\n",
        "\n",
        "# Rentang waktu\n",
        "start_date = \"2019-01-01\"\n",
        "end_date = \"2024-12-31\"\n",
        "\n",
        "# Ambil data historis menggunakan yfinance\n",
        "data = yf.download(ticker, start=start_date, end=end_date)\n",
        "\n",
        "# Simpan data ke file CSV\n",
        "data.to_csv(\"KLBF_JK_Historical.csv\")\n",
        "\n",
        "# Tampilkan 5 baris pertama\n",
        "print(data.head())\n",
        "#---SELESAI---"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypQybzV5nyDg",
        "outputId": "c65a4341-446a-4e7b-9155-bc9f963a2244"
      },
      "id": "ypQybzV5nyDg",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price         Adj Close   Close    High     Low    Open    Volume\n",
            "Ticker          KLBF.JK KLBF.JK KLBF.JK KLBF.JK KLBF.JK   KLBF.JK\n",
            "Date                                                             \n",
            "2019-01-01  1353.745850  1520.0  1520.0  1520.0  1520.0         0\n",
            "2019-01-02  1358.198853  1525.0  1530.0  1500.0  1525.0   5035800\n",
            "2019-01-03  1371.558228  1540.0  1545.0  1505.0  1535.0  15603900\n",
            "2019-01-04  1398.276855  1570.0  1575.0  1520.0  1535.0  19765600\n",
            "2019-01-07  1420.542480  1595.0  1610.0  1580.0  1580.0  28281300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Persiapan Dataset**"
      ],
      "metadata": {
        "id": "EVbiVnbEn5Hw"
      },
      "id": "EVbiVnbEn5Hw"
    },
    {
      "cell_type": "code",
      "source": [
        "#---MULAI---\n",
        "# Tambahkan target Next_Day_Close\n",
        "data['Next_Day_Close'] = data['Close'].shift(-1)\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Pilih fitur dan target\n",
        "features = ['Close']\n",
        "target = 'Next_Day_Close'\n",
        "\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "#---SELESAI---"
      ],
      "metadata": {
        "id": "_zG1p5wsn2tl"
      },
      "id": "_zG1p5wsn2tl",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Normalisasi Data**"
      ],
      "metadata": {
        "id": "4mhBkF6roApe"
      },
      "id": "4mhBkF6roApe"
    },
    {
      "cell_type": "code",
      "source": [
        "#---MULAI---\n",
        "# Normalisasi fitur\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "#---SELESAI---"
      ],
      "metadata": {
        "id": "vLRYLveXn9lq"
      },
      "id": "vLRYLveXn9lq",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Membagi Data Latih dan Uji**"
      ],
      "metadata": {
        "id": "9nIB_0GOoJNf"
      },
      "id": "9nIB_0GOoJNf"
    },
    {
      "cell_type": "code",
      "source": [
        "#---MULAI---\n",
        "# Bagi data menjadi data latih dan uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Data Training dan Testing untuk Skenario 2 (XGBoost-PSO)\n",
        "x_train2 = X_train.copy()  # Salin data latih untuk skenario 2\n",
        "y_train2 = y_train.copy()\n",
        "x_test2 = X_test.copy()    # Salin data uji untuk skenario 2\n",
        "y_test2 = y_test.copy()\n",
        "#---SELESAI---"
      ],
      "metadata": {
        "id": "KbvTXH4ioHGl"
      },
      "id": "KbvTXH4ioHGl",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. Melatih Model XGBoost**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gZIAA1xzoOrQ"
      },
      "id": "gZIAA1xzoOrQ"
    },
    {
      "cell_type": "code",
      "source": [
        "#---MULAI---\n",
        "# Train model XGBoost\n",
        "model = xgb.XGBRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Simpan model ke dalam file JSON\n",
        "model.save_model(\"xgboost_model_klbf.json\")\n",
        "print(\"Model berhasil disimpan sebagai 'xgboost_model_klbf.json'\")\n",
        "#---SELESAI---"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBBd_ZC4otL-",
        "outputId": "68d62fd7-5218-48ae-c555-2a0d96865cb8"
      },
      "id": "CBBd_ZC4otL-",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model berhasil disimpan sebagai 'xgboost_model_klbf.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7. Eksperimen Parameter XGBoost**"
      ],
      "metadata": {
        "id": "E-gSNXhnswyP"
      },
      "id": "E-gSNXhnswyP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **7.1 XGBoost tanpa optimasi PSO**\n",
        "\n"
      ],
      "metadata": {
        "id": "NzZQwjOPs6Vw"
      },
      "id": "NzZQwjOPs6Vw"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MULAI ---\n",
        "# Training Model XGBoost dengan Parameter default\n",
        "model_default = XGBRegressor(\n",
        "    max_depth=6,\n",
        "    gamma=0,\n",
        "    reg_lambda=1,\n",
        "    learning_rate=0.3,\n",
        "    min_child_weight=1,\n",
        "    subsample=1,\n",
        "    colsample_bytree=1\n",
        ")\n",
        "\n",
        "model_default.fit(X_train, y_train)\n",
        "\n",
        "# Simpan model default ke dalam file JSON\n",
        "model_default.save_model(\"xgboost_model_default.json\")\n",
        "print(\"Model default berhasil disimpan sebagai 'xgboost_model_default.json'\")\n",
        "# --- SELESAI ---"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8AvMG9NtB_R",
        "outputId": "b3f633f8-e26d-4a32-d96b-618e3762f06e"
      },
      "id": "r8AvMG9NtB_R",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model default berhasil disimpan sebagai 'xgboost_model_default.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **7.2 XGBoost dengan optimasi parameter PSO**"
      ],
      "metadata": {
        "id": "0gWpExI2uO4f"
      },
      "id": "0gWpExI2uO4f"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MULAI ---\n",
        "# Training Model XGBoost dengan optimasi parameter PSO\n",
        "def tune_xgboost(params):\n",
        "    max_depth = int(params[0])\n",
        "    gamma = params[1]\n",
        "    reg_lambda = params[2]\n",
        "    learning_rate = params[3]\n",
        "    min_child_weight = params[4]\n",
        "    subsample = params[5]\n",
        "    colsample_bytree = params[6]\n",
        "\n",
        "    model_pso = XGBRegressor(\n",
        "        max_depth=max_depth,\n",
        "        gamma=gamma,\n",
        "        reg_lambda=reg_lambda,\n",
        "        learning_rate=learning_rate,\n",
        "        min_child_weight=min_child_weight,\n",
        "        subsample=subsample,\n",
        "        colsample_bytree=colsample_bytree\n",
        "    )\n",
        "\n",
        "    model_pso.fit(x_train2, y_train2)\n",
        "    pred2 = model_pso.predict(x_test2)\n",
        "    mse2 = mean_squared_error(y_test2, pred2)\n",
        "\n",
        "    return mse2\n",
        "\n",
        "# Optimasi Parameter dengan PSO\n",
        "lb = [3, 0.01, 0.01, 0.01, 1, 0.5, 0.6]  # Lower Bound\n",
        "ub = [10, 0.5, 10, 0.3, 10, 0.9, 1]      # Upper Bound\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "best_params, _ = pso(\n",
        "    tune_xgboost,\n",
        "    lb,\n",
        "    ub,\n",
        "    swarmsize=100,\n",
        "    omega=0.6,\n",
        "    phip=1.5,\n",
        "    phig=1.5,\n",
        "    maxiter=100,\n",
        "    minfunc=1e-12,\n",
        "    debug=True\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(f\"\\nAlgoritma PSO Membutuhkan Waktu {elapsed_time} Detik\")\n",
        "\n",
        "# Best Parameter Hasil PSO\n",
        "best_max_depth = int(best_params[0])\n",
        "best_gamma = best_params[1]\n",
        "best_reg_lambda = best_params[2]\n",
        "best_learning_rate = best_params[3]\n",
        "best_min_child_weight = best_params[4]\n",
        "best_subsample = best_params[5]\n",
        "best_colsample_bytree = best_params[6]\n",
        "\n",
        "print('Best max_depth :', best_max_depth)\n",
        "print('Best gamma :', best_gamma)\n",
        "print('Best reg_lambda :', best_reg_lambda)\n",
        "print('Best learning_rate :', best_learning_rate)\n",
        "print('Best min_child_weight :', best_min_child_weight)\n",
        "print('Best subsample :', best_subsample)\n",
        "print('Best colsample_bytree :', best_colsample_bytree)\n",
        "\n",
        "# Latih ulang model dengan parameter terbaik\n",
        "model_pso = XGBRegressor(\n",
        "    max_depth=best_max_depth,\n",
        "    gamma=best_gamma,\n",
        "    reg_lambda=best_reg_lambda,\n",
        "    learning_rate=best_learning_rate,\n",
        "    min_child_weight=best_min_child_weight,\n",
        "    subsample=best_subsample,\n",
        "    colsample_bytree=best_colsample_bytree\n",
        ")\n",
        "\n",
        "model_pso.fit(x_train2, y_train2)\n",
        "\n",
        "# Simpan model PSO ke dalam file JSON\n",
        "model_pso.save_model(\"xgboost_model_pso.json\")\n",
        "print(\"Model hasil optimasi PSO telah disimpan ke file 'xgboost_model_pso.json'\")\n",
        "# --- SELESAI ---"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86A4c18DuTYx",
        "outputId": "75610a24-34b0-4bf6-b3cf-7c42edaef50f"
      },
      "id": "86A4c18DuTYx",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No constraints given.\n",
            "New best for swarm at iteration 1: [3.         0.44027456 0.01       0.04688124 3.24067835 0.7399615\n",
            " 0.6       ] 984.1779631420109\n",
            "New best for swarm at iteration 1: [3.         0.1778774  3.51389924 0.26820701 5.79654906 0.74766485\n",
            " 0.67766875] 980.4190859062483\n",
            "Best after iteration 1: [3.         0.1778774  3.51389924 0.26820701 5.79654906 0.74766485\n",
            " 0.67766875] 980.4190859062483\n",
            "New best for swarm at iteration 2: [3.         0.41775622 3.80655748 0.17109031 7.16354694 0.69252242\n",
            " 0.6706405 ] 973.0916982680864\n",
            "Best after iteration 2: [3.         0.41775622 3.80655748 0.17109031 7.16354694 0.69252242\n",
            " 0.6706405 ] 973.0916982680864\n",
            "Best after iteration 3: [3.         0.41775622 3.80655748 0.17109031 7.16354694 0.69252242\n",
            " 0.6706405 ] 973.0916982680864\n",
            "New best for swarm at iteration 4: [3.         0.41118023 3.14948286 0.1520003  7.04794331 0.80115777\n",
            " 0.6       ] 971.8238689052384\n",
            "New best for swarm at iteration 4: [3.         0.44432927 3.09811827 0.16980799 6.62363403 0.85956117\n",
            " 0.64192121] 960.989257374487\n",
            "Best after iteration 4: [3.         0.44432927 3.09811827 0.16980799 6.62363403 0.85956117\n",
            " 0.64192121] 960.989257374487\n",
            "Best after iteration 5: [3.         0.44432927 3.09811827 0.16980799 6.62363403 0.85956117\n",
            " 0.64192121] 960.989257374487\n",
            "Best after iteration 6: [3.         0.44432927 3.09811827 0.16980799 6.62363403 0.85956117\n",
            " 0.64192121] 960.989257374487\n",
            "Best after iteration 7: [3.         0.44432927 3.09811827 0.16980799 6.62363403 0.85956117\n",
            " 0.64192121] 960.989257374487\n",
            "New best for swarm at iteration 8: [3.         0.5        2.73897485 0.16622748 5.92001405 0.85779492\n",
            " 0.74742849] 958.1435984720533\n",
            "Best after iteration 8: [3.         0.5        2.73897485 0.16622748 5.92001405 0.85779492\n",
            " 0.74742849] 958.1435984720533\n",
            "New best for swarm at iteration 9: [3.         0.45497104 2.94357412 0.16646295 6.20610557 0.85527892\n",
            " 0.65213733] 956.5414300412954\n",
            "Best after iteration 9: [3.         0.45497104 2.94357412 0.16646295 6.20610557 0.85527892\n",
            " 0.65213733] 956.5414300412954\n",
            "Best after iteration 10: [3.         0.45497104 2.94357412 0.16646295 6.20610557 0.85527892\n",
            " 0.65213733] 956.5414300412954\n",
            "Best after iteration 11: [3.         0.45497104 2.94357412 0.16646295 6.20610557 0.85527892\n",
            " 0.65213733] 956.5414300412954\n",
            "Best after iteration 12: [3.         0.45497104 2.94357412 0.16646295 6.20610557 0.85527892\n",
            " 0.65213733] 956.5414300412954\n",
            "Best after iteration 13: [3.         0.45497104 2.94357412 0.16646295 6.20610557 0.85527892\n",
            " 0.65213733] 956.5414300412954\n",
            "New best for swarm at iteration 14: [3.         0.5        2.83334521 0.16653933 6.16300702 0.86122527\n",
            " 0.67577183] 955.9216156628135\n",
            "Best after iteration 14: [3.         0.5        2.83334521 0.16653933 6.16300702 0.86122527\n",
            " 0.67577183] 955.9216156628135\n",
            "Best after iteration 15: [3.         0.5        2.83334521 0.16653933 6.16300702 0.86122527\n",
            " 0.67577183] 955.9216156628135\n",
            "New best for swarm at iteration 16: [3.         0.5        2.96445833 0.16780342 6.08724338 0.86266944\n",
            " 0.68242357] 955.6534259460208\n",
            "Best after iteration 16: [3.         0.5        2.96445833 0.16780342 6.08724338 0.86266944\n",
            " 0.68242357] 955.6534259460208\n",
            "Best after iteration 17: [3.         0.5        2.96445833 0.16780342 6.08724338 0.86266944\n",
            " 0.68242357] 955.6534259460208\n",
            "Best after iteration 18: [3.         0.5        2.96445833 0.16780342 6.08724338 0.86266944\n",
            " 0.68242357] 955.6534259460208\n",
            "Best after iteration 19: [3.         0.5        2.96445833 0.16780342 6.08724338 0.86266944\n",
            " 0.68242357] 955.6534259460208\n",
            "Best after iteration 20: [3.         0.5        2.96445833 0.16780342 6.08724338 0.86266944\n",
            " 0.68242357] 955.6534259460208\n",
            "Best after iteration 21: [3.         0.5        2.96445833 0.16780342 6.08724338 0.86266944\n",
            " 0.68242357] 955.6534259460208\n",
            "Best after iteration 22: [3.         0.5        2.96445833 0.16780342 6.08724338 0.86266944\n",
            " 0.68242357] 955.6534259460208\n",
            "New best for swarm at iteration 23: [3.         0.5        2.81078585 0.16610733 6.09333358 0.86090116\n",
            " 0.68525447] 955.5121588611557\n",
            "New best for swarm at iteration 23: [3.         0.49795252 2.79946335 0.16626447 6.1208803  0.85909922\n",
            " 0.66878985] 955.0942667271486\n",
            "Best after iteration 23: [3.         0.49795252 2.79946335 0.16626447 6.1208803  0.85909922\n",
            " 0.66878985] 955.0942667271486\n",
            "Best after iteration 24: [3.         0.49795252 2.79946335 0.16626447 6.1208803  0.85909922\n",
            " 0.66878985] 955.0942667271486\n",
            "Best after iteration 25: [3.         0.49795252 2.79946335 0.16626447 6.1208803  0.85909922\n",
            " 0.66878985] 955.0942667271486\n",
            "Best after iteration 26: [3.         0.49795252 2.79946335 0.16626447 6.1208803  0.85909922\n",
            " 0.66878985] 955.0942667271486\n",
            "New best for swarm at iteration 27: [3.         0.49842594 2.94960113 0.16538809 6.12357945 0.86021081\n",
            " 0.67813274] 954.7720163573517\n",
            "New best for swarm at iteration 27: [3.         0.47492349 2.61363935 0.16560225 6.04764789 0.86065285\n",
            " 0.72476348] 953.5568050104415\n",
            "Best after iteration 27: [3.         0.47492349 2.61363935 0.16560225 6.04764789 0.86065285\n",
            " 0.72476348] 953.5568050104415\n",
            "Best after iteration 28: [3.         0.47492349 2.61363935 0.16560225 6.04764789 0.86065285\n",
            " 0.72476348] 953.5568050104415\n",
            "Best after iteration 29: [3.         0.47492349 2.61363935 0.16560225 6.04764789 0.86065285\n",
            " 0.72476348] 953.5568050104415\n",
            "Best after iteration 30: [3.         0.47492349 2.61363935 0.16560225 6.04764789 0.86065285\n",
            " 0.72476348] 953.5568050104415\n",
            "Best after iteration 31: [3.         0.47492349 2.61363935 0.16560225 6.04764789 0.86065285\n",
            " 0.72476348] 953.5568050104415\n",
            "Best after iteration 32: [3.         0.47492349 2.61363935 0.16560225 6.04764789 0.86065285\n",
            " 0.72476348] 953.5568050104415\n",
            "Best after iteration 33: [3.         0.47492349 2.61363935 0.16560225 6.04764789 0.86065285\n",
            " 0.72476348] 953.5568050104415\n",
            "New best for swarm at iteration 34: [3.         0.46599346 2.59046523 0.16550411 6.10372043 0.86057256\n",
            " 0.72069884] 953.5347021643174\n",
            "Best after iteration 34: [3.         0.46599346 2.59046523 0.16550411 6.10372043 0.86057256\n",
            " 0.72069884] 953.5347021643174\n",
            "Best after iteration 35: [3.         0.46599346 2.59046523 0.16550411 6.10372043 0.86057256\n",
            " 0.72069884] 953.5347021643174\n",
            "Best after iteration 36: [3.         0.46599346 2.59046523 0.16550411 6.10372043 0.86057256\n",
            " 0.72069884] 953.5347021643174\n",
            "Best after iteration 37: [3.         0.46599346 2.59046523 0.16550411 6.10372043 0.86057256\n",
            " 0.72069884] 953.5347021643174\n",
            "Best after iteration 38: [3.         0.46599346 2.59046523 0.16550411 6.10372043 0.86057256\n",
            " 0.72069884] 953.5347021643174\n",
            "New best for swarm at iteration 39: [3.         0.46713364 2.58800813 0.16563912 6.11351771 0.86058245\n",
            " 0.72013886] 953.534202464267\n",
            "Best after iteration 39: [3.         0.46713364 2.58800813 0.16563912 6.11351771 0.86058245\n",
            " 0.72013886] 953.534202464267\n",
            "New best for swarm at iteration 40: [3.         0.48331161 2.58511196 0.16543873 6.18689997 0.86057733\n",
            " 0.71373085] 953.5296525203046\n",
            "New best for swarm at iteration 40: [3.         0.48625994 2.60311807 0.165633   6.10660598 0.8595091\n",
            " 0.73928382] 953.45207929392\n",
            "New best for swarm at iteration 40: [3.         0.49970871 2.61192951 0.16623237 6.07180311 0.85979073\n",
            " 0.67242114] 952.6232691365516\n",
            "Best after iteration 40: [3.         0.49970871 2.61192951 0.16623237 6.07180311 0.85979073\n",
            " 0.67242114] 952.6232691365516\n",
            "Best after iteration 41: [3.         0.49970871 2.61192951 0.16623237 6.07180311 0.85979073\n",
            " 0.67242114] 952.6232691365516\n",
            "New best for swarm at iteration 42: [3.         0.49969446 2.61073323 0.166192   6.02801428 0.85988348\n",
            " 0.67746437] 952.606259576064\n",
            "Best after iteration 42: [3.         0.49969446 2.61073323 0.166192   6.02801428 0.85988348\n",
            " 0.67746437] 952.606259576064\n",
            "Best after iteration 43: [3.         0.49969446 2.61073323 0.166192   6.02801428 0.85988348\n",
            " 0.67746437] 952.606259576064\n",
            "Best after iteration 44: [3.         0.49969446 2.61073323 0.166192   6.02801428 0.85988348\n",
            " 0.67746437] 952.606259576064\n",
            "Best after iteration 45: [3.         0.49969446 2.61073323 0.166192   6.02801428 0.85988348\n",
            " 0.67746437] 952.606259576064\n",
            "New best for swarm at iteration 46: [3.         0.49411167 2.60563204 0.16555612 6.01730168 0.85956288\n",
            " 0.7109025 ] 952.5680491164403\n",
            "New best for swarm at iteration 46: [3.         0.49491378 2.83031585 0.16520504 6.09549776 0.85980686\n",
            " 0.7510138 ] 951.91170557359\n",
            "Best after iteration 46: [3.         0.49491378 2.83031585 0.16520504 6.09549776 0.85980686\n",
            " 0.7510138 ] 951.91170557359\n",
            "Best after iteration 47: [3.         0.49491378 2.83031585 0.16520504 6.09549776 0.85980686\n",
            " 0.7510138 ] 951.91170557359\n",
            "Best after iteration 48: [3.         0.49491378 2.83031585 0.16520504 6.09549776 0.85980686\n",
            " 0.7510138 ] 951.91170557359\n",
            "Best after iteration 49: [3.         0.49491378 2.83031585 0.16520504 6.09549776 0.85980686\n",
            " 0.7510138 ] 951.91170557359\n",
            "Best after iteration 50: [3.         0.49491378 2.83031585 0.16520504 6.09549776 0.85980686\n",
            " 0.7510138 ] 951.91170557359\n",
            "Best after iteration 51: [3.         0.49491378 2.83031585 0.16520504 6.09549776 0.85980686\n",
            " 0.7510138 ] 951.91170557359\n",
            "Best after iteration 52: [3.         0.49491378 2.83031585 0.16520504 6.09549776 0.85980686\n",
            " 0.7510138 ] 951.91170557359\n",
            "Best after iteration 53: [3.         0.49491378 2.83031585 0.16520504 6.09549776 0.85980686\n",
            " 0.7510138 ] 951.91170557359\n",
            "Best after iteration 54: [3.         0.49491378 2.83031585 0.16520504 6.09549776 0.85980686\n",
            " 0.7510138 ] 951.91170557359\n",
            "Best after iteration 55: [3.         0.49491378 2.83031585 0.16520504 6.09549776 0.85980686\n",
            " 0.7510138 ] 951.91170557359\n",
            "Best after iteration 56: [3.         0.49491378 2.83031585 0.16520504 6.09549776 0.85980686\n",
            " 0.7510138 ] 951.91170557359\n",
            "New best for swarm at iteration 57: [3.         0.49449951 2.83094736 0.16520128 6.11993523 0.85980562\n",
            " 0.74914168] 951.9112610997898\n",
            "Best after iteration 57: [3.         0.49449951 2.83094736 0.16520128 6.11993523 0.85980562\n",
            " 0.74914168] 951.9112610997898\n",
            "Best after iteration 58: [3.         0.49449951 2.83094736 0.16520128 6.11993523 0.85980562\n",
            " 0.74914168] 951.9112610997898\n",
            "Best after iteration 59: [3.         0.49449951 2.83094736 0.16520128 6.11993523 0.85980562\n",
            " 0.74914168] 951.9112610997898\n",
            "New best for swarm at iteration 60: [3.         0.49456816 2.83222589 0.16519563 6.12071797 0.85981314\n",
            " 0.75027551] 951.9104527624667\n",
            "Best after iteration 60: [3.         0.49456816 2.83222589 0.16519563 6.12071797 0.85981314\n",
            " 0.75027551] 951.9104527624667\n",
            "New best for swarm at iteration 61: [3.         0.49473459 2.83117761 0.16518194 6.119766   0.85980893\n",
            " 0.7515294 ] 951.9087773756105\n",
            "Best after iteration 61: [3.         0.49473459 2.83117761 0.16518194 6.119766   0.85980893\n",
            " 0.7515294 ] 951.9087773756105\n",
            "New best for swarm at iteration 62: [3.         0.49460101 2.83092405 0.1651753  6.12008892 0.8598105\n",
            " 0.75256697] 951.9062401737866\n",
            "Best after iteration 62: [3.         0.49460101 2.83092405 0.1651753  6.12008892 0.8598105\n",
            " 0.75256697] 951.9062401737866\n",
            "Best after iteration 63: [3.         0.49460101 2.83092405 0.1651753  6.12008892 0.8598105\n",
            " 0.75256697] 951.9062401737866\n",
            "New best for swarm at iteration 64: [3.         0.49458368 2.83041431 0.16517249 6.12204457 0.85980958\n",
            " 0.75116535] 951.9057386694412\n",
            "Best after iteration 64: [3.         0.49458368 2.83041431 0.16517249 6.12204457 0.85980958\n",
            " 0.75116535] 951.9057386694412\n",
            "New best for swarm at iteration 65: [3.         0.49601408 2.82156584 0.1651656  6.11615826 0.85981677\n",
            " 0.7435864 ] 951.9052800073789\n",
            "New best for swarm at iteration 65: [3.         0.48747956 2.82504369 0.16515823 6.15822852 0.85980583\n",
            " 0.74711591] 951.9040329337222\n",
            "Best after iteration 65: [3.         0.48747956 2.82504369 0.16515823 6.15822852 0.85980583\n",
            " 0.74711591] 951.9040329337222\n",
            "New best for swarm at iteration 66: [3.         0.48709352 2.82503705 0.16514583 6.19592913 0.85982336\n",
            " 0.74799186] 951.9037989436135\n",
            "Best after iteration 66: [3.         0.48709352 2.82503705 0.16514583 6.19592913 0.85982336\n",
            " 0.74799186] 951.9037989436135\n",
            "New best for swarm at iteration 67: [3.         0.48612186 2.82540714 0.16514939 6.16987686 0.85981082\n",
            " 0.74864243] 951.9037497949337\n",
            "Best after iteration 67: [3.         0.48612186 2.82540714 0.16514939 6.16987686 0.85981082\n",
            " 0.74864243] 951.9037497949337\n",
            "New best for swarm at iteration 68: [3.         0.49051368 2.8299048  0.16515172 6.18080792 0.85981164\n",
            " 0.75108895] 951.9034532458477\n",
            "Best after iteration 68: [3.         0.49051368 2.8299048  0.16515172 6.18080792 0.85981164\n",
            " 0.75108895] 951.9034532458477\n",
            "Best after iteration 69: [3.         0.49051368 2.8299048  0.16515172 6.18080792 0.85981164\n",
            " 0.75108895] 951.9034532458477\n",
            "Best after iteration 70: [3.         0.49051368 2.8299048  0.16515172 6.18080792 0.85981164\n",
            " 0.75108895] 951.9034532458477\n",
            "Best after iteration 71: [3.         0.49051368 2.8299048  0.16515172 6.18080792 0.85981164\n",
            " 0.75108895] 951.9034532458477\n",
            "New best for swarm at iteration 72: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 72: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 73: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 74: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 75: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 76: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 77: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 78: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 79: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 80: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 81: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 82: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 83: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 84: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 85: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 86: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 87: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "Best after iteration 88: [3.         0.48783646 2.82824624 0.1651424  6.17037698 0.85981944\n",
            " 0.75042658] 951.9017750331435\n",
            "New best for swarm at iteration 89: [3.         0.48771241 2.82804526 0.16514176 6.17502775 0.85982888\n",
            " 0.75044653] 951.9016903817248\n",
            "Best after iteration 89: [3.         0.48771241 2.82804526 0.16514176 6.17502775 0.85982888\n",
            " 0.75044653] 951.9016903817248\n",
            "Best after iteration 90: [3.         0.48771241 2.82804526 0.16514176 6.17502775 0.85982888\n",
            " 0.75044653] 951.9016903817248\n",
            "Best after iteration 91: [3.         0.48771241 2.82804526 0.16514176 6.17502775 0.85982888\n",
            " 0.75044653] 951.9016903817248\n",
            "Best after iteration 92: [3.         0.48771241 2.82804526 0.16514176 6.17502775 0.85982888\n",
            " 0.75044653] 951.9016903817248\n",
            "Best after iteration 93: [3.         0.48771241 2.82804526 0.16514176 6.17502775 0.85982888\n",
            " 0.75044653] 951.9016903817248\n",
            "Best after iteration 94: [3.         0.48771241 2.82804526 0.16514176 6.17502775 0.85982888\n",
            " 0.75044653] 951.9016903817248\n",
            "Best after iteration 95: [3.         0.48771241 2.82804526 0.16514176 6.17502775 0.85982888\n",
            " 0.75044653] 951.9016903817248\n",
            "Best after iteration 96: [3.         0.48771241 2.82804526 0.16514176 6.17502775 0.85982888\n",
            " 0.75044653] 951.9016903817248\n",
            "Best after iteration 97: [3.         0.48771241 2.82804526 0.16514176 6.17502775 0.85982888\n",
            " 0.75044653] 951.9016903817248\n",
            "Best after iteration 98: [3.         0.48771241 2.82804526 0.16514176 6.17502775 0.85982888\n",
            " 0.75044653] 951.9016903817248\n",
            "Best after iteration 99: [3.         0.48771241 2.82804526 0.16514176 6.17502775 0.85982888\n",
            " 0.75044653] 951.9016903817248\n",
            "Best after iteration 100: [3.         0.48771241 2.82804526 0.16514176 6.17502775 0.85982888\n",
            " 0.75044653] 951.9016903817248\n",
            "Stopping search: maximum iterations reached --> 100\n",
            "\n",
            "Algoritma PSO Membutuhkan Waktu 398.99213123321533 Detik\n",
            "Best max_depth : 3\n",
            "Best gamma : 0.4877124140374574\n",
            "Best reg_lambda : 2.8280452558715563\n",
            "Best learning_rate : 0.16514176386974036\n",
            "Best min_child_weight : 6.175027746366313\n",
            "Best subsample : 0.8598288761524644\n",
            "Best colsample_bytree : 0.7504465252656093\n",
            "Model hasil optimasi PSO telah disimpan ke file 'xgboost_model_pso.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MULAI ---\n",
        "# Training Best Model XGBoost dengan Parameter Terbaik hasil PSO\n",
        "best_model = XGBRegressor(\n",
        "    max_depth=3,  # Hasil dari PSO\n",
        "    gamma=0.4998,  # Hasil dari PSO\n",
        "    reg_lambda=2.8687,  # Hasil dari PSO\n",
        "    learning_rate=0.1643,  # Hasil dari PSO\n",
        "    min_child_weight=7.7663,  # Hasil dari PSO\n",
        "    subsample=0.8618,  # Hasil dari PSO\n",
        "    colsample_bytree=0.6009,  # Hasil dari PSO\n",
        "    random_state=42  # Untuk reproduktifitas\n",
        ")\n",
        "\n",
        "# Fit model ke data latih\n",
        "best_model.fit(x_train2, y_train2)\n",
        "\n",
        "# Simpan best model ke dalam file JSON\n",
        "best_model.save_model(\"best_xgboost_model.json\")\n",
        "\n",
        "print(\"Best model berhasil dilatih dan disimpan sebagai 'best_xgboost_model.json'\")\n",
        "# --- SELESAI ---"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0xKHPCuz6xm",
        "outputId": "556d399c-7d3e-463c-f33f-31f48a8199db"
      },
      "id": "e0xKHPCuz6xm",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model berhasil dilatih dan disimpan sebagai 'best_xgboost_model.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8. Prediksi dan Evaluasi Hasil**"
      ],
      "metadata": {
        "id": "8VzKd8MQo0Ge"
      },
      "id": "8VzKd8MQo0Ge"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# --- MULAI ---\n",
        "# Langkah 8: Prediksi dan Evaluasi\n",
        "\n",
        "# Prediksi data uji untuk Model 1 (XGBoost tanpa optimasi PSO)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Prediksi data uji untuk Model 2 (XGBoost dengan optimasi parameter dari PSO)\n",
        "y_pred2 = best_model.predict(x_test2)\n",
        "\n",
        "# Pastikan y_test dan y_test2 adalah numerik\n",
        "if y_test.dtype == 'object':\n",
        "    y_test = y_test.astype(float)\n",
        "\n",
        "if y_test2.dtype == 'object':\n",
        "    y_test2 = y_test2.astype(float)\n",
        "\n",
        "# Evaluasi Hasil untuk Model 1\n",
        "mse1 = mean_squared_error(y_test, y_pred)\n",
        "rmse1 = np.sqrt(mse1)\n",
        "mae1 = mean_absolute_error(y_test, y_pred)\n",
        "mape1 = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "r2_1 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Evaluasi Hasil untuk Model 2\n",
        "mse2 = mean_squared_error(y_test2, y_pred2)\n",
        "rmse2 = np.sqrt(mse2)\n",
        "mae2 = mean_absolute_error(y_test2, y_pred2)\n",
        "mape2 = np.mean(np.abs((y_test2 - y_pred2) / y_test2)) * 100\n",
        "r2_2 = r2_score(y_test2, y_pred2)\n",
        "\n",
        "# Evaluasi Hasil untuk Model 1\n",
        "mse1 = mean_squared_error(y_test, y_pred)\n",
        "rmse1 = np.sqrt(mse1)\n",
        "mae1 = mean_absolute_error(y_test, y_pred)\n",
        "mape1 = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "r2_1 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"=== Model 1: XGBoost tanpa optimasi PSO ===\")\n",
        "print(\"Mean Squared Error (MSE):\", mse1)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse1)\n",
        "print(\"Mean Absolute Error (MAE):\", mae1)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape1)\n",
        "print(\"R-squared:\", r2_1)\n",
        "\n",
        "# Evaluasi Hasil untuk Model 2\n",
        "mse2 = mean_squared_error(y_test2, y_pred2)\n",
        "rmse2 = np.sqrt(mse2)\n",
        "mae2 = mean_absolute_error(y_test2, y_pred2)\n",
        "mape2 = np.mean(np.abs((y_test2 - y_pred2) / y_test2)) * 100\n",
        "r2_2 = r2_score(y_test2, y_pred2)\n",
        "\n",
        "print(\"\\n=== Model 2: XGBoost dengan optimasi PSO ===\")\n",
        "print(\"Mean Squared Error (MSE):\", mse2)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse2)\n",
        "print(\"Mean Absolute Error (MAE):\", mae2)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape2)\n",
        "print(\"R-squared:\", r2_2)\n",
        "\n",
        "# Simpan hasil evaluasi ke file JSON\n",
        "results = {\n",
        "    \"Model 1 (XGBoost tanpa optimasi PSO)\": {\n",
        "        \"MSE\": mse1,\n",
        "        \"RMSE\": rmse1,\n",
        "        \"MAE\": mae1,\n",
        "        \"MAPE\": mape1,\n",
        "        \"R-squared\": r2_1\n",
        "    },\n",
        "    \"Model 2 (XGBoost dengan optimasi PSO)\": {\n",
        "        \"MSE\": mse2,\n",
        "        \"RMSE\": rmse2,\n",
        "        \"MAE\": mae2,\n",
        "        \"MAPE\": mape2,\n",
        "        \"R-squared\": r2_2\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(\"evaluation_results.json\", \"w\") as json_file:\n",
        "    json.dump(results, json_file, indent=4)\n",
        "\n",
        "# Simpan model ke dalam file JSON\n",
        "model.save_model(\"model_xgboost.json\")\n",
        "best_model.save_model(\"model_xgboost_pso.json\")\n",
        "\n",
        "print(\"\\nModel 1 dan Model 2 berhasil disimpan ke file JSON.\")\n",
        "print(\"\\nHasil evaluasi berhasil disimpan ke 'evaluation_results.json'.\")\n",
        "# --- SELESAI ---"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_wqQrCQ01LI",
        "outputId": "6624536b-da63-4329-f3e2-3782bf712357"
      },
      "id": "e_wqQrCQ01LI",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Model 1: XGBoost tanpa optimasi PSO ===\n",
            "Mean Squared Error (MSE): 1301.3777621840666\n",
            "Root Mean Squared Error (RMSE): 36.07461381891796\n",
            "Mean Absolute Error (MAE): 25.594521243556017\n",
            "Mean Absolute Percentage Error (MAPE): 1.6162268854489383\n",
            "R-squared: 0.9748007625479401\n",
            "\n",
            "=== Model 2: XGBoost dengan optimasi PSO ===\n",
            "Mean Squared Error (MSE): 1006.1296253362988\n",
            "Root Mean Squared Error (RMSE): 31.719546423874014\n",
            "Mean Absolute Error (MAE): 23.925730179767218\n",
            "Mean Absolute Percentage Error (MAPE): 1.4913570882534513\n",
            "R-squared: 0.980517801922594\n",
            "\n",
            "Model 1 dan Model 2 berhasil disimpan ke file JSON.\n",
            "\n",
            "Hasil evaluasi berhasil disimpan ke 'evaluation_results.json'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9. GUI**"
      ],
      "metadata": {
        "id": "8UGD0TIf1Q7N"
      },
      "id": "8UGD0TIf1Q7N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **9.1 Install Flask dan Ngrok**"
      ],
      "metadata": {
        "id": "mvGX-W7Z6ltt"
      },
      "id": "mvGX-W7Z6ltt"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghFXZq3w6uw1",
        "outputId": "10f29f24-5de0-4b76-98f7-c20953f95cc8"
      },
      "id": "ghFXZq3w6uw1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2024.12.14)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLDRX3kq9Tfz",
        "outputId": "c1d10628-ff9b-4499-f1ac-e332afe80897"
      },
      "id": "NLDRX3kq9Tfz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2qenvfvg5vXZgyTmQZbxGBx437m_3kRq219rNYWmuoBjrDpNm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrS3F0lD_a2i",
        "outputId": "0944732c-6ab0-4c5e-9855-c4a01fe2ea6c"
      },
      "id": "HrS3F0lD_a2i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **9.2 Backend Flask**"
      ],
      "metadata": {
        "id": "JxhP-6uo3Bk5"
      },
      "id": "JxhP-6uo3Bk5"
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, request\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "\n",
        "# Load model XGBoost tanpa optimasi\n",
        "model_default = xgb.Booster()\n",
        "model_default.load_model(\"model_xgboost.json\")\n",
        "\n",
        "# Load model XGBoost dengan optimasi PSO\n",
        "model_pso = xgb.Booster()\n",
        "model_pso.load_model(\"model_xgboost_pso.json\")\n",
        "\n",
        "# Inisialisasi Flask\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/predict', methods=[\"POST\"])\n",
        "def predict():\n",
        "    # Ambil input harga close\n",
        "    close_price = float(request.form['close'])\n",
        "\n",
        "    # Format input untuk model\n",
        "    input_data = np.array([[close_price]])\n",
        "    dmatrix = xgb.DMatrix(input_data)\n",
        "\n",
        "    # Prediksi dengan kedua model\n",
        "    predicted_close_default = model_default.predict(dmatrix)[0]\n",
        "    predicted_close_pso = model_pso.predict(dmatrix)[0]\n",
        "\n",
        "    # Contoh evaluasi metrik (statis untuk demo)\n",
        "    y_test = np.array([1500, 1520, 1535, 1550])\n",
        "    y_pred_default = np.array([1490, 1522, 1532, 1542])  # Contoh prediksi model default\n",
        "    y_pred_pso = np.array([1495, 1525, 1530, 1545])  # Contoh prediksi model PSO\n",
        "\n",
        "    # Metrik evaluasi untuk model default\n",
        "    mse_default = mean_squared_error(y_test, y_pred_default)\n",
        "    rmse_default = np.sqrt(mse_default)\n",
        "    mae_default = mean_absolute_error(y_test, y_pred_default)\n",
        "    mape_default = mean_absolute_percentage_error(y_test, y_pred_default)\n",
        "    r2_default = r2_score(y_test, y_pred_default)\n",
        "\n",
        "    # Metrik evaluasi untuk model PSO\n",
        "    mse_pso = mean_squared_error(y_test, y_pred_pso)\n",
        "    rmse_pso = np.sqrt(mse_pso)\n",
        "    mae_pso = mean_absolute_error(y_test, y_pred_pso)\n",
        "    mape_pso = mean_absolute_percentage_error(y_test, y_pred_pso)\n",
        "    r2_pso = r2_score(y_test, y_pred_pso)\n",
        "\n",
        "    metrics = {\n",
        "        'default': {\n",
        "            'mse': mse_default,\n",
        "            'rmse': rmse_default,\n",
        "            'mae': mae_default,\n",
        "            'mape': mape_default,\n",
        "            'r2': r2_default,\n",
        "        },\n",
        "        'pso': {\n",
        "            'mse': mse_pso,\n",
        "            'rmse': rmse_pso,\n",
        "            'mae': mae_pso,\n",
        "            'mape': mape_pso,\n",
        "            'r2': r2_pso,\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return render_template(\n",
        "        'index.html',\n",
        "        prediction_default=f\"Harga prediksi (Default): {predicted_close_default:.2f}\",\n",
        "        prediction_pso=f\"Harga prediksi (PSO): {predicted_close_pso:.2f}\",\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True, port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYkwzJgU3Esz",
        "outputId": "6c58efbe-917c-4ed5-8a05-e6eb14b08fad"
      },
      "id": "KYkwzJgU3Esz",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}