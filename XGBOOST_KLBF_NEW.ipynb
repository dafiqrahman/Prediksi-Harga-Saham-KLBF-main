{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "57fab3da",
      "metadata": {
        "id": "57fab3da"
      },
      "source": [
        "### **1. Mengimpor Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "Sn9iM4UetvzI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn9iM4UetvzI",
        "outputId": "b49167d3-6a48-4770-a86a-e2060b22e2a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyswarm\n",
            "  Downloading pyswarm-0.6.tar.gz (4.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyswarm) (1.26.4)\n",
            "Building wheels for collected packages: pyswarm\n",
            "  Building wheel for pyswarm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyswarm: filename=pyswarm-0.6-py3-none-any.whl size=4464 sha256=28f65c3c1b431a68fc38037b1e42298084907afe0a0f11a065bc228204186f50\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/67/40/62fa158f497f942277cbab8199b05cb61c571ab324e67ad0d6\n",
            "Successfully built pyswarm\n",
            "Installing collected packages: pyswarm\n",
            "Successfully installed pyswarm-0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install pyswarm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "s2xWBighnZBE",
      "metadata": {
        "id": "s2xWBighnZBE"
      },
      "outputs": [],
      "source": [
        "#---MULAI---\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import time\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from xgboost import XGBRegressor\n",
        "from pyswarm import pso\n",
        "#---SELESAI---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZdW26fUPnmm1",
      "metadata": {
        "id": "ZdW26fUPnmm1"
      },
      "source": [
        "### **2. Mengambil Data dari Yahoo Finance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "ypQybzV5nyDg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypQybzV5nyDg",
        "outputId": "448ac7cd-3dea-4f69-8c67-73fd0f2243cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Price         Adj Close   Close    High     Low    Open    Volume\n",
            "Ticker          KLBF.JK KLBF.JK KLBF.JK KLBF.JK KLBF.JK   KLBF.JK\n",
            "Date                                                             \n",
            "2019-01-01  1353.745850  1520.0  1520.0  1520.0  1520.0         0\n",
            "2019-01-02  1358.198975  1525.0  1530.0  1500.0  1525.0   5035800\n",
            "2019-01-03  1371.558350  1540.0  1545.0  1505.0  1535.0  15603900\n",
            "2019-01-04  1398.276978  1570.0  1575.0  1520.0  1535.0  19765600\n",
            "2019-01-07  1420.542480  1595.0  1610.0  1580.0  1580.0  28281300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#---MULAI---\n",
        "# Ticker saham\n",
        "ticker = \"KLBF.JK\"\n",
        "\n",
        "# Rentang waktu\n",
        "start_date = \"2019-01-01\"\n",
        "end_date = \"2024-12-31\"\n",
        "\n",
        "# Ambil data historis menggunakan yfinance\n",
        "data = yf.download(ticker, start=start_date, end=end_date)\n",
        "\n",
        "# Simpan data ke file CSV\n",
        "data.to_csv(\"KLBF_JK_Historical.csv\")\n",
        "\n",
        "# Tampilkan 5 baris pertama\n",
        "print(data.head())\n",
        "#---SELESAI---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EVbiVnbEn5Hw",
      "metadata": {
        "id": "EVbiVnbEn5Hw"
      },
      "source": [
        "### **3. Persiapan Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "_zG1p5wsn2tl",
      "metadata": {
        "id": "_zG1p5wsn2tl"
      },
      "outputs": [],
      "source": [
        "#---MULAI---\n",
        "# Tambahkan target Next_Day_Close\n",
        "data['Next_Day_Close'] = data['Close'].shift(-1)\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Pilih fitur dan target\n",
        "features = ['Close']\n",
        "target = 'Next_Day_Close'\n",
        "\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "#---SELESAI---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4mhBkF6roApe",
      "metadata": {
        "id": "4mhBkF6roApe"
      },
      "source": [
        "### **4. Normalisasi Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "vLRYLveXn9lq",
      "metadata": {
        "id": "vLRYLveXn9lq"
      },
      "outputs": [],
      "source": [
        "#---MULAI---\n",
        "# Normalisasi fitur\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "#---SELESAI---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9nIB_0GOoJNf",
      "metadata": {
        "id": "9nIB_0GOoJNf"
      },
      "source": [
        "### **5. Membagi Data Latih dan Uji**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "KbvTXH4ioHGl",
      "metadata": {
        "id": "KbvTXH4ioHGl"
      },
      "outputs": [],
      "source": [
        "#---MULAI---\n",
        "# Bagi data menjadi data latih dan uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Data Training dan Testing untuk Skenario 2 (XGBoost-PSO)\n",
        "x_train2 = X_train.copy()  # Salin data latih untuk skenario 2\n",
        "y_train2 = y_train.copy()\n",
        "x_test2 = X_test.copy()    # Salin data uji untuk skenario 2\n",
        "y_test2 = y_test.copy()\n",
        "#---SELESAI---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gZIAA1xzoOrQ",
      "metadata": {
        "id": "gZIAA1xzoOrQ"
      },
      "source": [
        "### **6. Melatih Model XGBoost**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "CBBd_ZC4otL-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBBd_ZC4otL-",
        "outputId": "41f63859-6f2e-46d6-c97c-be9a49e5c343"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['xgboost_model_klbf.pkl']"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#---MULAI---\n",
        "# Train model XGBoost\n",
        "model = xgb.XGBRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Simpan model ke file\n",
        "joblib.dump(model, \"xgboost_model_klbf.pkl\")\n",
        "#---SELESAI---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E-gSNXhnswyP",
      "metadata": {
        "id": "E-gSNXhnswyP"
      },
      "source": [
        "### **7. Eksperimen Parameter XGBoost**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NzZQwjOPs6Vw",
      "metadata": {
        "id": "NzZQwjOPs6Vw"
      },
      "source": [
        "#### **7.1 XGBoost tanpa optimasi PSO**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "r8AvMG9NtB_R",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8AvMG9NtB_R",
        "outputId": "aee5c502-0039-402b-dc0f-fa1eaa6d2d95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['xgboost_model_default.pkl']"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --- MULAI ---\n",
        "# Training Model XGBoost dengan Parameter default\n",
        "model_default = XGBRegressor(\n",
        "    max_depth=6,\n",
        "    gamma=0,\n",
        "    reg_lambda=1,\n",
        "    learning_rate=0.3,\n",
        "    min_child_weight=1,\n",
        "    subsample=1,\n",
        "    colsample_bytree=1\n",
        ")\n",
        "\n",
        "model_default.fit(X_train, y_train)\n",
        "\n",
        "# Simpan model default ke file\n",
        "joblib.dump(model_default, \"xgboost_model_default.pkl\")\n",
        "# --- SELESAI ---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0gWpExI2uO4f",
      "metadata": {
        "id": "0gWpExI2uO4f"
      },
      "source": [
        "#### **7.2 XGBoost dengan optimasi parameter PSO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "86A4c18DuTYx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86A4c18DuTYx",
        "outputId": "64494252-3259-4fa2-91d8-2475ce48bf18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No constraints given.\n",
            "New best for swarm at iteration 1: [3.         0.5        4.03528943 0.17938565 5.63835559 0.76131467\n",
            " 0.74925144] 975.2607071276273\n",
            "Best after iteration 1: [3.         0.5        4.03528943 0.17938565 5.63835559 0.76131467\n",
            " 0.74925144] 975.2607071276273\n",
            "New best for swarm at iteration 2: [ 3.          0.5        10.          0.17068648  7.54830102  0.71361746\n",
            "  0.6777502 ] 975.2054248584852\n",
            "Best after iteration 2: [ 3.          0.5        10.          0.17068648  7.54830102  0.71361746\n",
            "  0.6777502 ] 975.2054248584852\n",
            "New best for swarm at iteration 3: [3.         0.5        3.41016308 0.13316224 5.17368702 0.8707542\n",
            " 0.69170206] 973.5773520143766\n",
            "New best for swarm at iteration 3: [3.         0.46196467 4.33602708 0.08426528 5.75951213 0.85379348\n",
            " 0.61864825] 973.2636335963244\n",
            "Best after iteration 3: [3.         0.46196467 4.33602708 0.08426528 5.75951213 0.85379348\n",
            " 0.61864825] 973.2636335963244\n",
            "New best for swarm at iteration 4: [3.         0.5        4.12886558 0.10610223 5.01076248 0.8594461\n",
            " 0.6       ] 968.6731791087509\n",
            "Best after iteration 4: [3.         0.5        4.12886558 0.10610223 5.01076248 0.8594461\n",
            " 0.6       ] 968.6731791087509\n",
            "New best for swarm at iteration 5: [3.         0.5        3.74393038 0.1307801  6.66256568 0.87418674\n",
            " 0.6       ] 968.3767688721292\n",
            "Best after iteration 5: [3.         0.5        3.74393038 0.1307801  6.66256568 0.87418674\n",
            " 0.6       ] 968.3767688721292\n",
            "New best for swarm at iteration 6: [3.         0.5        4.60436195 0.1980614  7.47891616 0.87041087\n",
            " 0.6       ] 962.1211264852029\n",
            "New best for swarm at iteration 6: [3.         0.5        4.90648623 0.17155504 7.53537735 0.86040298\n",
            " 0.6       ] 961.3177838593493\n",
            "Best after iteration 6: [3.         0.5        4.90648623 0.17155504 7.53537735 0.86040298\n",
            " 0.6       ] 961.3177838593493\n",
            "New best for swarm at iteration 7: [3.         0.5        4.93987387 0.17510996 6.0317355  0.87814727\n",
            " 0.6       ] 960.5492568530497\n",
            "Best after iteration 7: [3.         0.5        4.93987387 0.17510996 6.0317355  0.87814727\n",
            " 0.6       ] 960.5492568530497\n",
            "Best after iteration 8: [3.         0.5        4.93987387 0.17510996 6.0317355  0.87814727\n",
            " 0.6       ] 960.5492568530497\n",
            "New best for swarm at iteration 9: [3.         0.5        4.86966764 0.17469962 5.91906431 0.87858947\n",
            " 0.6       ] 958.602538774563\n",
            "Best after iteration 9: [3.         0.5        4.86966764 0.17469962 5.91906431 0.87858947\n",
            " 0.6       ] 958.602538774563\n",
            "Best after iteration 10: [3.         0.5        4.86966764 0.17469962 5.91906431 0.87858947\n",
            " 0.6       ] 958.602538774563\n",
            "New best for swarm at iteration 11: [3.         0.5        4.21540418 0.20244311 5.51725216 0.86852768\n",
            " 0.6       ] 958.5214601001214\n",
            "Best after iteration 11: [3.         0.5        4.21540418 0.20244311 5.51725216 0.86852768\n",
            " 0.6       ] 958.5214601001214\n",
            "New best for swarm at iteration 12: [3.         0.48744472 4.50215771 0.26275522 6.3145971  0.86962355\n",
            " 0.6       ] 957.62048658313\n",
            "Best after iteration 12: [3.         0.48744472 4.50215771 0.26275522 6.3145971  0.86962355\n",
            " 0.6       ] 957.62048658313\n",
            "New best for swarm at iteration 13: [3.         0.49472885 3.39800565 0.15662789 7.27625077 0.86202759\n",
            " 0.68025829] 956.19674444153\n",
            "Best after iteration 13: [3.         0.49472885 3.39800565 0.15662789 7.27625077 0.86202759\n",
            " 0.68025829] 956.19674444153\n",
            "Best after iteration 14: [3.         0.49472885 3.39800565 0.15662789 7.27625077 0.86202759\n",
            " 0.68025829] 956.19674444153\n",
            "Best after iteration 15: [3.         0.49472885 3.39800565 0.15662789 7.27625077 0.86202759\n",
            " 0.68025829] 956.19674444153\n",
            "Best after iteration 16: [3.         0.49472885 3.39800565 0.15662789 7.27625077 0.86202759\n",
            " 0.68025829] 956.19674444153\n",
            "Best after iteration 17: [3.         0.49472885 3.39800565 0.15662789 7.27625077 0.86202759\n",
            " 0.68025829] 956.19674444153\n",
            "Best after iteration 18: [3.         0.49472885 3.39800565 0.15662789 7.27625077 0.86202759\n",
            " 0.68025829] 956.19674444153\n",
            "Best after iteration 19: [3.         0.49472885 3.39800565 0.15662789 7.27625077 0.86202759\n",
            " 0.68025829] 956.19674444153\n",
            "Best after iteration 20: [3.         0.49472885 3.39800565 0.15662789 7.27625077 0.86202759\n",
            " 0.68025829] 956.19674444153\n",
            "New best for swarm at iteration 21: [3.         0.49443322 3.3116033  0.17208999 7.00523105 0.86337034\n",
            " 0.66023886] 954.6634446078924\n",
            "Best after iteration 21: [3.         0.49443322 3.3116033  0.17208999 7.00523105 0.86337034\n",
            " 0.66023886] 954.6634446078924\n",
            "Best after iteration 22: [3.         0.49443322 3.3116033  0.17208999 7.00523105 0.86337034\n",
            " 0.66023886] 954.6634446078924\n",
            "Best after iteration 23: [3.         0.49443322 3.3116033  0.17208999 7.00523105 0.86337034\n",
            " 0.66023886] 954.6634446078924\n",
            "Best after iteration 24: [3.         0.49443322 3.3116033  0.17208999 7.00523105 0.86337034\n",
            " 0.66023886] 954.6634446078924\n",
            "New best for swarm at iteration 25: [3.         0.49592957 3.14302022 0.16724832 7.84248403 0.85995642\n",
            " 0.66734428] 954.2069989783297\n",
            "Best after iteration 25: [3.         0.49592957 3.14302022 0.16724832 7.84248403 0.85995642\n",
            " 0.66734428] 954.2069989783297\n",
            "New best for swarm at iteration 26: [3.         0.49924596 2.88097052 0.1625471  7.99235109 0.86260083\n",
            " 0.63904067] 953.6145938304792\n",
            "Best after iteration 26: [3.         0.49924596 2.88097052 0.1625471  7.99235109 0.86260083\n",
            " 0.63904067] 953.6145938304792\n",
            "Best after iteration 27: [3.         0.49924596 2.88097052 0.1625471  7.99235109 0.86260083\n",
            " 0.63904067] 953.6145938304792\n",
            "Best after iteration 28: [3.         0.49924596 2.88097052 0.1625471  7.99235109 0.86260083\n",
            " 0.63904067] 953.6145938304792\n",
            "Best after iteration 29: [3.         0.49924596 2.88097052 0.1625471  7.99235109 0.86260083\n",
            " 0.63904067] 953.6145938304792\n",
            "Best after iteration 30: [3.         0.49924596 2.88097052 0.1625471  7.99235109 0.86260083\n",
            " 0.63904067] 953.6145938304792\n",
            "New best for swarm at iteration 31: [3.0174787  0.49861192 2.67676235 0.16266693 7.8229544  0.86183218\n",
            " 0.64622083] 952.9833371408005\n",
            "Best after iteration 31: [3.0174787  0.49861192 2.67676235 0.16266693 7.8229544  0.86183218\n",
            " 0.64622083] 952.9833371408005\n",
            "Best after iteration 32: [3.0174787  0.49861192 2.67676235 0.16266693 7.8229544  0.86183218\n",
            " 0.64622083] 952.9833371408005\n",
            "Best after iteration 33: [3.0174787  0.49861192 2.67676235 0.16266693 7.8229544  0.86183218\n",
            " 0.64622083] 952.9833371408005\n",
            "Best after iteration 34: [3.0174787  0.49861192 2.67676235 0.16266693 7.8229544  0.86183218\n",
            " 0.64622083] 952.9833371408005\n",
            "New best for swarm at iteration 35: [3.01593118 0.5        2.64844914 0.16447784 7.89741508 0.86149378\n",
            " 0.62373158] 950.8109011110679\n",
            "New best for swarm at iteration 35: [3.01057399 0.5        2.85237763 0.16471271 7.87508965 0.86144379\n",
            " 0.60321623] 950.3088424829576\n",
            "Best after iteration 35: [3.01057399 0.5        2.85237763 0.16471271 7.87508965 0.86144379\n",
            " 0.60321623] 950.3088424829576\n",
            "Best after iteration 36: [3.01057399 0.5        2.85237763 0.16471271 7.87508965 0.86144379\n",
            " 0.60321623] 950.3088424829576\n",
            "Best after iteration 37: [3.01057399 0.5        2.85237763 0.16471271 7.87508965 0.86144379\n",
            " 0.60321623] 950.3088424829576\n",
            "Best after iteration 38: [3.01057399 0.5        2.85237763 0.16471271 7.87508965 0.86144379\n",
            " 0.60321623] 950.3088424829576\n",
            "Best after iteration 39: [3.01057399 0.5        2.85237763 0.16471271 7.87508965 0.86144379\n",
            " 0.60321623] 950.3088424829576\n",
            "Best after iteration 40: [3.01057399 0.5        2.85237763 0.16471271 7.87508965 0.86144379\n",
            " 0.60321623] 950.3088424829576\n",
            "Best after iteration 41: [3.01057399 0.5        2.85237763 0.16471271 7.87508965 0.86144379\n",
            " 0.60321623] 950.3088424829576\n",
            "New best for swarm at iteration 42: [3.01083259 0.5        2.85740323 0.16476421 7.88338713 0.86147968\n",
            " 0.6       ] 950.2942333591303\n",
            "Best after iteration 42: [3.01083259 0.5        2.85740323 0.16476421 7.88338713 0.86147968\n",
            " 0.6       ] 950.2942333591303\n",
            "Best after iteration 43: [3.01083259 0.5        2.85740323 0.16476421 7.88338713 0.86147968\n",
            " 0.6       ] 950.2942333591303\n",
            "Best after iteration 44: [3.01083259 0.5        2.85740323 0.16476421 7.88338713 0.86147968\n",
            " 0.6       ] 950.2942333591303\n",
            "Best after iteration 45: [3.01083259 0.5        2.85740323 0.16476421 7.88338713 0.86147968\n",
            " 0.6       ] 950.2942333591303\n",
            "New best for swarm at iteration 46: [3.01320821 0.49949745 2.85823506 0.16470454 7.85046336 0.86149442\n",
            " 0.6       ] 950.2858370529221\n",
            "Best after iteration 46: [3.01320821 0.49949745 2.85823506 0.16470454 7.85046336 0.86149442\n",
            " 0.6       ] 950.2858370529221\n",
            "Best after iteration 47: [3.01320821 0.49949745 2.85823506 0.16470454 7.85046336 0.86149442\n",
            " 0.6       ] 950.2858370529221\n",
            "New best for swarm at iteration 48: [3.01370065 0.49942026 2.85915183 0.16482967 7.80752809 0.86138586\n",
            " 0.6       ] 950.265825963028\n",
            "Best after iteration 48: [3.01370065 0.49942026 2.85915183 0.16482967 7.80752809 0.86138586\n",
            " 0.6       ] 950.265825963028\n",
            "Best after iteration 49: [3.01370065 0.49942026 2.85915183 0.16482967 7.80752809 0.86138586\n",
            " 0.6       ] 950.265825963028\n",
            "Best after iteration 50: [3.01370065 0.49942026 2.85915183 0.16482967 7.80752809 0.86138586\n",
            " 0.6       ] 950.265825963028\n",
            "Best after iteration 51: [3.01370065 0.49942026 2.85915183 0.16482967 7.80752809 0.86138586\n",
            " 0.6       ] 950.265825963028\n",
            "New best for swarm at iteration 52: [3.01517786 0.49937593 2.86311147 0.16479552 7.90010747 0.86139333\n",
            " 0.6       ] 950.2609053553037\n",
            "Best after iteration 52: [3.01517786 0.49937593 2.86311147 0.16479552 7.90010747 0.86139333\n",
            " 0.6       ] 950.2609053553037\n",
            "Best after iteration 53: [3.01517786 0.49937593 2.86311147 0.16479552 7.90010747 0.86139333\n",
            " 0.6       ] 950.2609053553037\n",
            "New best for swarm at iteration 54: [3.015147   0.49920228 2.86462693 0.16476971 7.87289287 0.86139286\n",
            " 0.6       ] 950.2575600593649\n",
            "Best after iteration 54: [3.015147   0.49920228 2.86462693 0.16476971 7.87289287 0.86139286\n",
            " 0.6       ] 950.2575600593649\n",
            "Best after iteration 55: [3.015147   0.49920228 2.86462693 0.16476971 7.87289287 0.86139286\n",
            " 0.6       ] 950.2575600593649\n",
            "Best after iteration 56: [3.015147   0.49920228 2.86462693 0.16476971 7.87289287 0.86139286\n",
            " 0.6       ] 950.2575600593649\n",
            "Best after iteration 57: [3.015147   0.49920228 2.86462693 0.16476971 7.87289287 0.86139286\n",
            " 0.6       ] 950.2575600593649\n",
            "Best after iteration 58: [3.015147   0.49920228 2.86462693 0.16476971 7.87289287 0.86139286\n",
            " 0.6       ] 950.2575600593649\n",
            "Best after iteration 59: [3.015147   0.49920228 2.86462693 0.16476971 7.87289287 0.86139286\n",
            " 0.6       ] 950.2575600593649\n",
            "New best for swarm at iteration 60: [3.01507324 0.49922177 2.86323082 0.16473379 7.79685706 0.86138799\n",
            " 0.6000073 ] 950.2537962189515\n",
            "Best after iteration 60: [3.01507324 0.49922177 2.86323082 0.16473379 7.79685706 0.86138799\n",
            " 0.6000073 ] 950.2537962189515\n",
            "Best after iteration 61: [3.01507324 0.49922177 2.86323082 0.16473379 7.79685706 0.86138799\n",
            " 0.6000073 ] 950.2537962189515\n",
            "Best after iteration 62: [3.01507324 0.49922177 2.86323082 0.16473379 7.79685706 0.86138799\n",
            " 0.6000073 ] 950.2537962189515\n",
            "Best after iteration 63: [3.01507324 0.49922177 2.86323082 0.16473379 7.79685706 0.86138799\n",
            " 0.6000073 ] 950.2537962189515\n",
            "New best for swarm at iteration 64: [3.01505111 0.49921676 2.8634809  0.1647294  7.79047759 0.86138857\n",
            " 0.6       ] 950.2525702140667\n",
            "Best after iteration 64: [3.01505111 0.49921676 2.8634809  0.1647294  7.79047759 0.86138857\n",
            " 0.6       ] 950.2525702140667\n",
            "Best after iteration 65: [3.01505111 0.49921676 2.8634809  0.1647294  7.79047759 0.86138857\n",
            " 0.6       ] 950.2525702140667\n",
            "New best for swarm at iteration 66: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "Best after iteration 66: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "Best after iteration 67: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "Best after iteration 68: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "Best after iteration 69: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "Best after iteration 70: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "Best after iteration 71: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "Best after iteration 72: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "Best after iteration 73: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "Best after iteration 74: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "Best after iteration 75: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "Best after iteration 76: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "Best after iteration 77: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "Best after iteration 78: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "Best after iteration 79: [3.01509178 0.49921633 2.86331686 0.16472736 7.78114198 0.86138802\n",
            " 0.6       ] 950.2522177105757\n",
            "New best for swarm at iteration 80: [3.01510959 0.49921961 2.86337048 0.1647274  7.7680728  0.86138922\n",
            " 0.60000036] 950.2518550184283\n",
            "Best after iteration 80: [3.01510959 0.49921961 2.86337048 0.1647274  7.7680728  0.86138922\n",
            " 0.60000036] 950.2518550184283\n",
            "New best for swarm at iteration 81: [3.01510356 0.49922094 2.86339192 0.16472712 7.77952333 0.86138843\n",
            " 0.60000037] 950.2518108614347\n",
            "Best after iteration 81: [3.01510356 0.49922094 2.86339192 0.16472712 7.77952333 0.86138843\n",
            " 0.60000037] 950.2518108614347\n",
            "Best after iteration 82: [3.01510356 0.49922094 2.86339192 0.16472712 7.77952333 0.86138843\n",
            " 0.60000037] 950.2518108614347\n",
            "Best after iteration 83: [3.01510356 0.49922094 2.86339192 0.16472712 7.77952333 0.86138843\n",
            " 0.60000037] 950.2518108614347\n",
            "Best after iteration 84: [3.01510356 0.49922094 2.86339192 0.16472712 7.77952333 0.86138843\n",
            " 0.60000037] 950.2518108614347\n",
            "Best after iteration 85: [3.01510356 0.49922094 2.86339192 0.16472712 7.77952333 0.86138843\n",
            " 0.60000037] 950.2518108614347\n",
            "Best after iteration 86: [3.01510356 0.49922094 2.86339192 0.16472712 7.77952333 0.86138843\n",
            " 0.60000037] 950.2518108614347\n",
            "Best after iteration 87: [3.01510356 0.49922094 2.86339192 0.16472712 7.77952333 0.86138843\n",
            " 0.60000037] 950.2518108614347\n",
            "Best after iteration 88: [3.01510356 0.49922094 2.86339192 0.16472712 7.77952333 0.86138843\n",
            " 0.60000037] 950.2518108614347\n",
            "Best after iteration 89: [3.01510356 0.49922094 2.86339192 0.16472712 7.77952333 0.86138843\n",
            " 0.60000037] 950.2518108614347\n",
            "Best after iteration 90: [3.01510356 0.49922094 2.86339192 0.16472712 7.77952333 0.86138843\n",
            " 0.60000037] 950.2518108614347\n",
            "Best after iteration 91: [3.01510356 0.49922094 2.86339192 0.16472712 7.77952333 0.86138843\n",
            " 0.60000037] 950.2518108614347\n",
            "New best for swarm at iteration 92: [3.01306542 0.49912934 2.87162827 0.16446216 7.75002532 0.86177506\n",
            " 0.60076728] 950.0866200823945\n",
            "Best after iteration 92: [3.01306542 0.49912934 2.87162827 0.16446216 7.75002532 0.86177506\n",
            " 0.60076728] 950.0866200823945\n",
            "New best for swarm at iteration 93: [3.01264538 0.49980799 2.86871446 0.16430906 7.76630681 0.86183589\n",
            " 0.600965  ] 950.0610635383372\n",
            "Best after iteration 93: [3.01264538 0.49980799 2.86871446 0.16430906 7.76630681 0.86183589\n",
            " 0.600965  ] 950.0610635383372\n",
            "Best after iteration 94: [3.01264538 0.49980799 2.86871446 0.16430906 7.76630681 0.86183589\n",
            " 0.600965  ] 950.0610635383372\n",
            "Best after iteration 95: [3.01264538 0.49980799 2.86871446 0.16430906 7.76630681 0.86183589\n",
            " 0.600965  ] 950.0610635383372\n",
            "Best after iteration 96: [3.01264538 0.49980799 2.86871446 0.16430906 7.76630681 0.86183589\n",
            " 0.600965  ] 950.0610635383372\n",
            "Best after iteration 97: [3.01264538 0.49980799 2.86871446 0.16430906 7.76630681 0.86183589\n",
            " 0.600965  ] 950.0610635383372\n",
            "Best after iteration 98: [3.01264538 0.49980799 2.86871446 0.16430906 7.76630681 0.86183589\n",
            " 0.600965  ] 950.0610635383372\n",
            "Best after iteration 99: [3.01264538 0.49980799 2.86871446 0.16430906 7.76630681 0.86183589\n",
            " 0.600965  ] 950.0610635383372\n",
            "Best after iteration 100: [3.01264538 0.49980799 2.86871446 0.16430906 7.76630681 0.86183589\n",
            " 0.600965  ] 950.0610635383372\n",
            "Stopping search: maximum iterations reached --> 100\n",
            "\n",
            "Algoritma PSO Membutuhkan Waktu 381.78535890579224 Detik\n",
            "Best max_depth : 3\n",
            "Best gamma : 0.499807991314997\n",
            "Best reg_lambda : 2.86871446480062\n",
            "Best learning_rate : 0.1643090608222523\n",
            "Best min_child_weight : 7.766306813665048\n",
            "Best subsample : 0.8618358880007962\n",
            "Best colsample_bytree : 0.600965004926232\n",
            "Model hasil optimasi PSO telah disimpan ke file 'xgboost_model_pso.pkl'\n"
          ]
        }
      ],
      "source": [
        "# --- MULAI ---\n",
        "# Training Model XGBoost dengan optimasi parameter PSO\n",
        "def tune_xgboost(params):\n",
        "    max_depth = int(params[0])\n",
        "    gamma = params[1]\n",
        "    reg_lambda = params[2]\n",
        "    learning_rate = params[3]\n",
        "    min_child_weight = params[4]\n",
        "    subsample = params[5]\n",
        "    colsample_bytree = params[6]\n",
        "\n",
        "    model_pso = XGBRegressor(\n",
        "        max_depth=max_depth,\n",
        "        gamma=gamma,\n",
        "        reg_lambda=reg_lambda,\n",
        "        learning_rate=learning_rate,\n",
        "        min_child_weight=min_child_weight,\n",
        "        subsample=subsample,\n",
        "        colsample_bytree=colsample_bytree\n",
        "    )\n",
        "\n",
        "    model_pso.fit(x_train2, y_train2)\n",
        "    pred2 = model_pso.predict(x_test2)\n",
        "    mse2 = mean_squared_error(y_test2, pred2)\n",
        "\n",
        "    return mse2\n",
        "\n",
        "# Optimasi Parameter dengan PSO\n",
        "lb = [3, 0.01, 0.01, 0.01, 1, 0.5, 0.6]  # Lower Bound\n",
        "ub = [10, 0.5, 10, 0.3, 10, 0.9, 1]      # Upper Bound\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "best_params, _ = pso(\n",
        "    tune_xgboost,\n",
        "    lb,\n",
        "    ub,\n",
        "    swarmsize=100,\n",
        "    omega=0.6,\n",
        "    phip=1.5,\n",
        "    phig=1.5,\n",
        "    maxiter=100,\n",
        "    minfunc=1e-12,\n",
        "    debug=True\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(f\"\\nAlgoritma PSO Membutuhkan Waktu {elapsed_time} Detik\")\n",
        "\n",
        "# Best Parameter Hasil PSO\n",
        "best_max_depth = int(best_params[0])\n",
        "best_gamma = best_params[1]\n",
        "best_reg_lambda = best_params[2]\n",
        "best_learning_rate = best_params[3]\n",
        "best_min_child_weight = best_params[4]\n",
        "best_subsample = best_params[5]\n",
        "best_colsample_bytree = best_params[6]\n",
        "\n",
        "print('Best max_depth :', best_max_depth)\n",
        "print('Best gamma :', best_gamma)\n",
        "print('Best reg_lambda :', best_reg_lambda)\n",
        "print('Best learning_rate :', best_learning_rate)\n",
        "print('Best min_child_weight :', best_min_child_weight)\n",
        "print('Best subsample :', best_subsample)\n",
        "print('Best colsample_bytree :', best_colsample_bytree)\n",
        "\n",
        "# Latih ulang model dengan parameter terbaik\n",
        "model_pso = XGBRegressor(\n",
        "    max_depth=best_max_depth,\n",
        "    gamma=best_gamma,\n",
        "    reg_lambda=best_reg_lambda,\n",
        "    learning_rate=best_learning_rate,\n",
        "    min_child_weight=best_min_child_weight,\n",
        "    subsample=best_subsample,\n",
        "    colsample_bytree=best_colsample_bytree\n",
        ")\n",
        "\n",
        "model_pso.fit(x_train2, y_train2)\n",
        "\n",
        "# Simpan model PSO ke file setelah eksperimen\n",
        "joblib.dump(model_pso, \"xgboost_model_pso.pkl\")\n",
        "print(\"Model hasil optimasi PSO telah disimpan ke file 'xgboost_model_pso.pkl'\")\n",
        "# --- SELESAI ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "e0xKHPCuz6xm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0xKHPCuz6xm",
        "outputId": "607e8467-b370-497d-90ed-dedbdfbca2ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model berhasil dilatih dan disimpan sebagai 'best_xgboost_model.pkl'\n"
          ]
        }
      ],
      "source": [
        "# --- MULAI ---\n",
        "# Training Best Model XGBoost dengan Parameter Terbaik hasil PSO\n",
        "best_model = XGBRegressor(\n",
        "    max_depth=3,  # Hasil dari PSO\n",
        "    gamma=0.4998,  # Hasil dari PSO\n",
        "    reg_lambda=2.8687,  # Hasil dari PSO\n",
        "    learning_rate=0.1643,  # Hasil dari PSO\n",
        "    min_child_weight=7.7663,  # Hasil dari PSO\n",
        "    subsample=0.8618,  # Hasil dari PSO\n",
        "    colsample_bytree=0.6009,  # Hasil dari PSO\n",
        "    random_state=42  # Untuk reproduktifitas\n",
        ")\n",
        "\n",
        "# Fit model ke data latih\n",
        "best_model.fit(x_train2, y_train2)\n",
        "\n",
        "# Simpan best model ke file\n",
        "joblib.dump(best_model, \"best_xgboost_model.pkl\")\n",
        "\n",
        "print(\"Best model berhasil dilatih dan disimpan sebagai 'best_xgboost_model.pkl'\")\n",
        "# --- SELESAI ---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8VzKd8MQo0Ge",
      "metadata": {
        "id": "8VzKd8MQo0Ge"
      },
      "source": [
        "### **8. Prediksi dan Evaluasi Hasil**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "e_wqQrCQ01LI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_wqQrCQ01LI",
        "outputId": "5c2fe3cf-bfae-4705-81de-7e27bfa6c09e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Model 1: XGBoost tanpa optimasi PSO ===\n",
            "Mean Squared Error (MSE): 1302.852330038552\n",
            "Root Mean Squared Error (RMSE): 36.09504578246926\n",
            "Mean Absolute Error (MAE): 25.611528046277105\n",
            "Mean Absolute Percentage Error (MAPE): 1.6174815854351117\n",
            "R-squared: 0.974775906029878\n",
            "\n",
            "=== Model 2: XGBoost dengan optimasi PSO ===\n",
            "Mean Squared Error (MSE): 1004.3639280906036\n",
            "Root Mean Squared Error (RMSE): 31.69170124954802\n",
            "Mean Absolute Error (MAE): 23.90872337704613\n",
            "Mean Absolute Percentage Error (MAPE): 1.4901853443630326\n",
            "R-squared: 0.9805548414672531\n",
            "\n",
            "Model 1 dan Model 2 berhasil disimpan ke file.\n"
          ]
        }
      ],
      "source": [
        "#---MULAI---\n",
        "# Langkah 8: Prediksi dan Evaluasi\n",
        "\n",
        "# Prediksi data uji untuk Model 1 (XGBoost tanpa optimasi PSO)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Prediksi data uji untuk Model 2 (XGBoost dengan optimasi parameter dari PSO)\n",
        "y_pred2 = best_model.predict(x_test2)\n",
        "\n",
        "# Pastikan y_test dan y_test2 adalah numerik\n",
        "if y_test.dtype == 'object':\n",
        "    y_test = y_test.astype(float)\n",
        "\n",
        "if y_test2.dtype == 'object':\n",
        "    y_test2 = y_test2.astype(float)\n",
        "\n",
        "# Evaluasi Hasil untuk Model 1\n",
        "mse1 = mean_squared_error(y_test, y_pred)\n",
        "rmse1 = np.sqrt(mse1)\n",
        "mae1 = mean_absolute_error(y_test, y_pred)\n",
        "mape1 = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "r2_1 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"=== Model 1: XGBoost tanpa optimasi PSO ===\")\n",
        "print(\"Mean Squared Error (MSE):\", mse1)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse1)\n",
        "print(\"Mean Absolute Error (MAE):\", mae1)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape1)\n",
        "print(\"R-squared:\", r2_1)\n",
        "\n",
        "# Evaluasi Hasil untuk Model 2\n",
        "mse2 = mean_squared_error(y_test2, y_pred2)\n",
        "rmse2 = np.sqrt(mse2)\n",
        "mae2 = mean_absolute_error(y_test2, y_pred2)\n",
        "mape2 = np.mean(np.abs((y_test2 - y_pred2) / y_test2)) * 100\n",
        "r2_2 = r2_score(y_test2, y_pred2)\n",
        "\n",
        "print(\"\\n=== Model 2: XGBoost dengan optimasi PSO ===\")\n",
        "print(\"Mean Squared Error (MSE):\", mse2)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse2)\n",
        "print(\"Mean Absolute Error (MAE):\", mae2)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape2)\n",
        "print(\"R-squared:\", r2_2)\n",
        "\n",
        "# Save Model\n",
        "pickle.dump(model, open('model_xgboost.pkl', 'wb'))\n",
        "pickle.dump(best_model, open('model_xgboost_pso.pkl', 'wb'))\n",
        "\n",
        "print(\"\\nModel 1 dan Model 2 berhasil disimpan ke file.\")\n",
        "#---SELESAI---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8UGD0TIf1Q7N",
      "metadata": {
        "id": "8UGD0TIf1Q7N"
      },
      "source": [
        "### **9. GUI**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JxhP-6uo3Bk5",
      "metadata": {
        "id": "JxhP-6uo3Bk5"
      },
      "source": [
        "#### **9.1 Backend Flask**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "KYkwzJgU3Esz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYkwzJgU3Esz",
        "outputId": "9560cdee-7041-419d-fa4e-a9633e3eb082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, render_template, request\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "import numpy as np\n",
        "\n",
        "# Load model\n",
        "model = pickle.load(open(\"model_xgboost_pso.pkl\", \"rb\"))\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/predict', methods=[\"POST\"])\n",
        "def predict():\n",
        "    close_price = float(request.form['close'])\n",
        "\n",
        "    # Predict next day close price\n",
        "    input_data = [[close_price]]\n",
        "    predicted_close = model.predict(input_data)[0]\n",
        "\n",
        "    # Example evaluation metrics (static for demo)\n",
        "    y_test = np.array([1500, 1520, 1535, 1550])\n",
        "    y_pred = np.array([1495, 1525, 1530, 1545])\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    metrics = {\n",
        "        'mse': mse,\n",
        "        'rmse': rmse,\n",
        "        'mae': mae,\n",
        "        'mape': mape,\n",
        "        'r2': r2\n",
        "    }\n",
        "\n",
        "    return render_template(\n",
        "        'index.html',\n",
        "        prediction=f\"Harga prediksi untuk hari berikutnya: {predicted_close:.2f}\",\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True, port=5000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "breast-cancer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
